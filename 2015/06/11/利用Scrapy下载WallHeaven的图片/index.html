<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>利用Scrapy下载WallHeaven的图片 | Eric's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">利用Scrapy下载WallHeaven的图片</h1><a id="logo" href="/.">Eric's Blog</a><p class="description">д�ֵĵط�</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">利用Scrapy下载WallHeaven的图片</h1><div class="post-meta">Jun 11, 2015<span> | </span><span class="category"><a href="/categories/Python/">Python</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p>稍微试了一下怎么使用scrapy,确实非常方便.</p>
<p>##Scrapy的安装<br>安装指南可以戳<a href="http://scrapy-chs.readthedocs.org/zh_CN/latest/intro/install.html" target="_blank" rel="external">这里</a>因为安装太久了所以也忘了有啥需要的地方</p>
<p>##开始用scrapy创建项目<br>在磁盘的任意位置(最好还是先新建一个文件夹)按住shift,鼠标右键打开CMD,输入以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scrapy startproject wallheaven_download</div></pre></td></tr></table></figure></p>
<p>该命令会创建包含下列内容的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">wallheaven_download/</div><div class="line">    scrapy.cfg</div><div class="line">    tutorial/</div><div class="line">        __init__.py</div><div class="line">        items.py</div><div class="line">        pipelines.py</div><div class="line">        settings.py</div><div class="line">        spiders/</div><div class="line">            __init__.py</div></pre></td></tr></table></figure></p>
<p>这些文件分别是:</p>
<blockquote>
<p>scrapy.cfg: 项目的配置文件<br>tutorial/: 该项目的python模块。之后您将在此加入代码。<br>tutorial/items.py: 项目中的item文件.<br>tutorial/pipelines.py: 项目中的pipelines文件.<br>tutorial/settings.py: 项目的设置文件.<br>tutorial/spiders/: 放置spider代码的目录.</p>
<p>##定义Item<br><code>Item</code>是保存爬取到数据的一个容易,在抓wallheaven这个项目里,我们需要保存的信息都储存在里面,主要是图片的下载地址还有在本地保存的地址.<br>我们编辑<code>wallheaven</code>文件夹里的<code>items.py</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">import scrapy</div><div class="line"></div><div class="line"></div><div class="line">class WallheavenDownloadItem(scrapy.Item):</div><div class="line">    # define the fields for your item here like:</div><div class="line">    # name = scrapy.Field()</div><div class="line">    image_urls = scrapy.Field()</div><div class="line">    images = scrapy.Field()</div><div class="line">    image_paths = scrapy.Field()</div></pre></td></tr></table></figure></p>
</blockquote>
<p>##编写第一个爬虫<br>编辑<code>wallheaven</code>文件夹里的<code>wallheaven_spider.py</code><br>一个正常的spider需要包含以下三个属性:</p>
<blockquote>
<ul>
<li>name: 用于区别Spider。 该名字必须是唯一的，您不可以为不同    的Spider设定相同的名字。</li>
<li>start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。</li>
<li>parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">class WallHeaven(Spider):</div><div class="line">    name = &apos;wallheaven_image&apos; #spider的名字</div><div class="line">    allowed_domains = [&apos;wallhaven.cc&apos;]</div><div class="line">    start_urls = [&apos;http://alpha.wallhaven.cc/random?page=1&apos;] # 需要爬取的原始页面</div><div class="line">    for i in range(2, 5288): </div><div class="line">        new_url = &apos;http://alpha.wallhaven.cc/random?page=&apos; + str(i)</div><div class="line">        start_urls.append(new_url) # 生成包含所有需要下载的URL的列表</div><div class="line"></div><div class="line">    def parse(self, response):</div><div class="line">        req = []</div><div class="line">        hxs = Selector(response)</div><div class="line">        page_urls = hxs.xpath(&apos;//div[@id=&quot;thumbs&quot;]//ul/li/figure/a/@href&apos;).extract() # 提取抓取页面的所有的image的链接,可以用chrome F12模式,找到图片,右键复制XPATH</div><div class="line">        for url in page_urls:</div><div class="line">            r = Request(url, callback=self.parse_image_page)</div><div class="line">            req.append(r)</div><div class="line">        return req</div><div class="line"></div><div class="line">    def parse_image_page(self, response):</div><div class="line">        hxs = Selector(response)</div><div class="line">        download_link = hxs.xpath(&apos;//img[@id=&quot;wallpaper&quot;]/@src&apos;).extract() #打开某一张图片所在页面获取下载地址</div><div class="line">        #  特别注意一下download_link返回的是一个list</div><div class="line">        for link in download_link:</div><div class="line">            real_download_link = re.split(r&apos;//&apos;, link)[1]</div><div class="line">            postfix = re.split(r&apos;/&apos;, link)[-1]</div><div class="line">            Item = WallheavenDownloadItem() #将获取到的下载地址存到ITEM里面,item结构类似于字典</div><div class="line">            Item[&apos;image_urls&apos;] = [&quot;http://&quot; + real_download_link] </div><div class="line">        return Item</div></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<p>##修改配置文件<code>settings.py</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">BOT_NAME = &apos;wallheaven_download&apos;</div><div class="line">SPIDER_MODULES = [&apos;wallheaven_download.spiders&apos;]</div><div class="line">NEWSPIDER_MODULE = &apos;wallheaven_download.spiders&apos;</div><div class="line">ITEM_PIPELINES = &#123;&apos;wallheaven_download.pipelines.MyImagesPipeline&apos;: 1&#125; # 处理图片下载的管道,将对应的权值调大</div><div class="line">IMAGES_STORE = &apos;./image&apos;</div></pre></td></tr></table></figure></p>
<p>##下载图片<br><code>Scrapy</code>提供了一个<code>Item pipeline</code>用来下载这个项目的图片</p>
<blockquote>
<p>这条管道，被称作图片管道，在 ImagesPipeline 类中实现，提供了一个方便并具有额外特性的方法，来下载并本地存储图片:<br>将所有下载的图片转换成通用的格式（JPG）和模式（RGB）<br>避免重新下载最近已经下载过的图片<br>缩略图生成<br>检测图像的宽/高，确保它们满足最小限制</p>
</blockquote>
<p>在我们这个项目里没有下载缩略图,壁纸当然要下载原始的</p>
<p>##使用图片管道<br>当使用 <code>ImagesPipeline</code> ，典型的工作流程如下所示:</p>
<p>在一个爬虫里，你抓取一个项目，把其中图片的URL放入 image_urls 组内,就是我们在spider里面做的<br>项目从爬虫内返回，进入项目管道。<br>当项目进入 ImagesPipeline，image_urls 组内的URLs将被Scrapy的调度器和下载器（这意味着调度器和下载器的中间件可以复用）安排下载，当优先级更高，会在其他页面被抓取前处理。项目会在这个特定的管道阶段保持“locker”的状态，直到完成图片的下载（或者由于某些原因未完成下载）。<br>当图片下载完，另一个组(images)将被更新到结构中。这个组将包含一个字典列表，其中包括下载图片的信息，比如下载路径、源抓取地址（从 image_urls 组获得）和图片的校验码。 images 列表中的图片顺序将和源 image_urls 组保持一致。如果某个图片下载失败，将会记录下错误信息，图片也不会出现在 images 组中。</p>
<p>代码如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">import scrapy</div><div class="line">from scrapy.contrib.pipeline.images import ImagesPipeline</div><div class="line">from scrapy.exceptions import DropItem</div><div class="line"></div><div class="line">class MyImagesPipeline(ImagesPipeline):</div><div class="line"></div><div class="line">    def file_path(self, request, response=None, info=None):</div><div class="line">        image_guid = request.url.split(&apos;/&apos;)[-1]</div><div class="line">        return &apos;full/%s&apos; % (image_guid) #生成下载图片的名字</div><div class="line"></div><div class="line">    def get_media_requests(self, item, info):</div><div class="line">        for image_url in item[&apos;image_urls&apos;]:</div><div class="line">            yield scrapy.Request(image_url)</div><div class="line"></div><div class="line">    def item_completed(self, results, item, info):</div><div class="line">        image_paths = [x[&apos;path&apos;] for ok, x in results if ok]</div><div class="line">        if not image_paths:</div><div class="line">            raise DropItem(&quot;Item contains no images&quot;)</div><div class="line">        item[&apos;image_paths&apos;] = image_paths</div><div class="line">        return item</div><div class="line"></div><div class="line">class WallheavenDownloadPipeline(object):</div><div class="line">    def process_item(self, item, spider):</div><div class="line">        return item</div></pre></td></tr></table></figure></p>
<p>最后在根目录输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scrapy crawl wallheaven_image</div></pre></td></tr></table></figure></p>
<p>就可以了<br>在目录下会新建一个full文件夹,图片会源源不断的下载进来<br>不过有一个问题,停不下来,接不上去,我还没想好怎么去解决,sigh</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2015/06/11/利用Scrapy下载WallHeaven的图片/" data-id="ciyvg9q2s0008ugubpdk6ltcs" class="article-share-link">Aktie</a><div class="tags"><a href="/tags/python-Scrapy/">python,Scrapy</a></div><div class="post-nav"><a href="/2015/08/29/利用requests模块模拟登录百度并请求百小度/" class="pre">利用requests模块模拟登录百度并请求百小度</a><a href="/2015/05/29/naive-bayes-classifier-scratch-python/" class="next">机器学习之用Python从零实现贝叶斯分类器</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python-机器学习/">Python,机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Python-Machine-Learning/" style="font-size: 15px;">Python,Machine Learning</a> <a href="/tags/python-编程语言/" style="font-size: 15px;">python,编程语言</a> <a href="/tags/python-机器学习/" style="font-size: 15px;">python,机器学习</a> <a href="/tags/python-Scrapy/" style="font-size: 15px;">python,Scrapy</a> <a href="/tags/python-requests/" style="font-size: 15px;">python,requests</a> <a href="/tags/python-nao/" style="font-size: 15px;">python,nao</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/02/07/图灵机器人api接入nao机器/">将图灵机器人api接入nao机器人</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/08/29/利用requests模块模拟登录百度并请求百小度/">利用requests模块模拟登录百度并请求百小度</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/06/11/利用Scrapy下载WallHeaven的图片/">利用Scrapy下载WallHeaven的图片</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/05/29/naive-bayes-classifier-scratch-python/">机器学习之用Python从零实现贝叶斯分类器</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/04/20/Building-machine-learning-system/">Building machine learning system</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/04/20/About-python-decorator/">关于python装饰器</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Eric's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>